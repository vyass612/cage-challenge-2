{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the CybORG environment, it is necessary to import the CybORG class. CybORG stands for __Cyb__er __O__perations __R__esearch __G__ym, so remember to capitalise correctly when importing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\c21122256\\PycharmProjects\\CAGE-Challenge-1\\venv\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from CybORG import CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALthough CybORG uses an OpenAI gym API, it is not run by calling gym.make(). Instead it has to be manually instantiated. The constructor has two mandatory string parameters: a mode-type which specifies which engine will be used under the hood and the path to a .yaml scenario file which defines the network layout and agent action spaces.\n",
    "\n",
    "The only currently supported mode is simulation, while this challenge uses Scenario 1b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "path = str(inspect.getfile(CybORG))\n",
    "path = path[:-10] + '/Shared/Scenarios/Scenario1b.yaml'\n",
    "\n",
    "env = CybORG(path, 'sim')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Agent with CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario 1b has multiple actors involved: Red team will be attacking the network, Blue team will be defending the network, while Green team represents noise generated by users. Normally the roles of Red and Green will be handled by internal rules-based agents, while Blue team interacts with the external API. However, for demonstration purposes, it will be easier to first examine a Red agent.\n",
    "\n",
    "CybORG uses an OpenAI Gym interface to interact with agents. Thus, we can begin the scenario by calling the reset method. It is necessary to specify which team you are on as a string parameter. Without using any wrappers, CybORG will return a results object which contains various bits of data. We can get the observation by accessing the corresponding attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': <TrinaryEnum.UNKNOWN: 2>, 'User0': {'Interface': [{'Interface Name': 'eth0', 'IP Address': IPv4Address('10.0.4.162'), 'Subnet': IPv4Network('10.0.4.160/28')}], 'Sessions': [{'Username': 'SYSTEM', 'ID': 0, 'Timeout': 0, 'PID': 6934, 'Type': <SessionType.RED_ABSTRACT_SESSION: 10>, 'Agent': 'Red'}], 'Processes': [{'PID': 6934, 'Username': 'SYSTEM'}], 'System info': {'Hostname': 'User0', 'OSType': <OperatingSystemType.WINDOWS: 2>, 'OSDistribution': <OperatingSystemDistribution.WINDOWS_SVR_2008: 4>, 'OSVersion': <OperatingSystemVersion.W6_1_7601: 13>, 'Architecture': <Architecture.x64: 2>}}}\n"
     ]
    }
   ],
   "source": [
    "results = env.reset(agent='Red')\n",
    "obs = results.observation\n",
    "print(obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the above observation outputs a messy dictionary. In order to understand raw CybORG observations, please go to the observation tutorial. We will show how to train a neural network-based agent with CybORG down below.\n",
    "\n",
    "Because of the complexties of Cybersecurity, the action space in CybORG is generated on the fly. For Scenario 1b, this only needs to be extracted at the beginning of the scenario. This can also be found in the results object. It is another messy dictionary, so we will only print out the keys. You can learn more in the action_space tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': {<class 'CybORG.Shared.Actions.Action.Sleep'>: True, <class 'CybORG.Shared.Actions.AbstractActions.DiscoverRemoteSystems.DiscoverRemoteSystems'>: True, <class 'CybORG.Shared.Actions.AbstractActions.DiscoverNetworkServices.DiscoverNetworkServices'>: True, <class 'CybORG.Shared.Actions.AbstractActions.ExploitRemoteService.ExploitRemoteService'>: True, <class 'CybORG.Shared.Actions.AbstractActions.PrivilegeEscalate.PrivilegeEscalate'>: True, <class 'CybORG.Shared.Actions.AbstractActions.Impact.Impact'>: True}, 'subnet': {IPv4Network('10.0.197.0/28'): False, IPv4Network('10.0.171.64/28'): False, IPv4Network('10.0.4.160/28'): True}, 'ip_address': {IPv4Address('10.0.197.1'): False, IPv4Address('10.0.197.5'): False, IPv4Address('10.0.197.9'): False, IPv4Address('10.0.197.14'): False, IPv4Address('10.0.171.71'): False, IPv4Address('10.0.171.69'): False, IPv4Address('10.0.171.75'): False, IPv4Address('10.0.171.77'): False, IPv4Address('10.0.4.162'): True, IPv4Address('10.0.4.173'): False, IPv4Address('10.0.4.161'): False, IPv4Address('10.0.4.169'): False, IPv4Address('10.0.4.164'): False}, 'session': {0: True}, 'username': {'root': False, 'ubuntu': False, 'www-data': False, 'pi': False, 'GreenAgent': False, 'Administrator': False, 'vagrant': False, 'SYSTEM': False}, 'password': {'raspberry': False, 'vagrant': False}, 'process': {1: False, 389: False, 407: False, 409: False, 560: False, 790: False, 802: False, 803: False, 807: False, 824: False, 825: False, 827: False, 832: False, 844: False, 847: False, 852: False, 853: False, 863: False, 867: False, 875: False, 884: False, 1370: False, 1432: False, 2288: False, 879: False, 1615: False, 13906: False, 1091: False, 7640: False, 3368: False, 4400: False, 4: False, 3404: False, 8597: False, 11875: False, 10669: False, 995: False, 10888: False, 6332: False, 28706: False, 28948: False, 1043: False, 19717: False, 31510: False, 185: False, 6934: True, 1189: False, 22561: False, 2207: False, 19551: False, 1100: False, 2673: False, 29526: False, 30468: False, 23461: False}, 'port': {22: False, 135: False, 3389: False, 445: False, 139: False, 80: False, 443: False}, 'target_session': {0: False, 1: False, 2: False, 3: False, 4: False, 5: False, 6: False, 7: False}, 'agent': {'Red': True}, 'hostname': {'Defender': False, 'Enterprise0': False, 'Enterprise1': False, 'Enterprise2': False, 'Op_Host0': False, 'Op_Host1': False, 'Op_Host2': False, 'Op_Server0': False, 'User0': True, 'User1': False, 'User2': False, 'User3': False, 'User4': False}}\n",
      "['action', 'subnet', 'ip_address', 'session', 'username', 'password', 'process', 'port', 'target_session', 'agent', 'hostname']\n"
     ]
    }
   ],
   "source": [
    "action_space = results.action_space\n",
    "print(action_space)\n",
    "\n",
    "print(list(action_space.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like OpenAI gym, CybORG uses a step function to input actions and return results. The method itself requires two string parameters: agent is the name of the team that is taking the action and action is the action being performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscoverRemoteSystems 10.0.4.160/28\n"
     ]
    }
   ],
   "source": [
    "from CybORG.Agents import B_lineAgent,RedMeanderAgent\n",
    "\n",
    "agent = B_lineAgent()\n",
    "\n",
    "action = agent.get_action(obs,action_space)\n",
    "\n",
    "results = env.step(agent='Red',action=action)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results object contains the new observation, reward and done attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': <TrinaryEnum.TRUE: 1>, '10.0.4.162': {'Interface': [{'IP Address': IPv4Address('10.0.4.162'), 'Subnet': IPv4Network('10.0.4.160/28')}]}, '10.0.4.173': {'Interface': [{'IP Address': IPv4Address('10.0.4.173'), 'Subnet': IPv4Network('10.0.4.160/28')}]}, '10.0.4.161': {'Interface': [{'IP Address': IPv4Address('10.0.4.161'), 'Subnet': IPv4Network('10.0.4.160/28')}]}, '10.0.4.169': {'Interface': [{'IP Address': IPv4Address('10.0.4.169'), 'Subnet': IPv4Network('10.0.4.160/28')}]}, '10.0.4.164': {'Interface': [{'IP Address': IPv4Address('10.0.4.164'), 'Subnet': IPv4Network('10.0.4.160/28')}]}}\n",
      "----------------------------------------------------------------------------\n",
      "DiscoverRemoteSystems 10.0.4.160/28\n",
      "----------------------------------------------------------------------------\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(results.observation)\n",
    "print(76*'-')\n",
    "print(results.action)\n",
    "print(76*'-')\n",
    "print(results.done)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Opponents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, only Red Team performed any actions. In order to setup CybORG for the full challenge, we want a Blue Agent to be interacting with the external API while Red and Green take their actions automatically in the background.\n",
    "\n",
    "We can achieve this by specifying an agents dictionary to pass into CybORG when instantiating the class. Now, whenever the step function is called, the agents will take turn to perform their actions. Note that the turn order is Blue, Green then Red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscoverRemoteSystems 10.0.179.112/28\n",
      "-0.1\n",
      "DiscoverNetworkServices 10.0.179.116\n",
      "-0.1\n",
      "ExploitRemoteService 10.0.179.116\n",
      "-0.2\n",
      "PrivilegeEscalate User1\n",
      "-0.2\n",
      "DiscoverNetworkServices 10.0.105.27\n",
      "-0.2\n",
      "ExploitRemoteService 10.0.105.27\n",
      "-0.2\n",
      "PrivilegeEscalate Enterprise1\n",
      "-1.2\n",
      "DiscoverRemoteSystems 10.0.105.16/28\n",
      "-1.2\n",
      "DiscoverNetworkServices 10.0.105.19\n",
      "-1.2\n",
      "ExploitRemoteService 10.0.105.19\n",
      "-1.2\n",
      "PrivilegeEscalate Enterprise2\n",
      "-2.2\n",
      "DiscoverNetworkServices 10.0.243.194\n",
      "-2.2\n",
      "-2.2\n",
      "PrivilegeEscalate Op_Server0\n",
      "-3.2\n",
      "Impact Op_Server0\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n",
      "-13.2\n"
     ]
    }
   ],
   "source": [
    "from CybORG.Agents import B_lineAgent, GreenAgent, BlueMonitorAgent,RedMeanderAgent\n",
    "\n",
    "agents = {\n",
    "    'Red': B_lineAgent,\n",
    "    'Green': GreenAgent\n",
    "}\n",
    "\n",
    "env = CybORG(path,'sim',agents=agents)\n",
    "\n",
    "results = env.reset(agent='Blue')\n",
    "obs = results.observation\n",
    "action_space = results.action_space\n",
    "agent = BlueMonitorAgent()\n",
    "\n",
    "for step in range(100):\n",
    "    action = agent.get_action(obs,action_space=action_space)\n",
    "    results = env.step(agent='Blue',action=action)\n",
    "    obs = results.observation\n",
    "    reward = results.reward\n",
    "    print(reward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Neural Network with CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a Neural network with CybORG, we will need to import a wrapper. The Challenge Wrapper provides all the functionality needed for the Scenario1b challenge and makes the external api much more in line with OpenAI gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from CybORG.Agents.Wrappers import ChallengeWrapper\n",
    "cyborg = CybORG(path,'sim',agents=agents)\n",
    "env = ChallengeWrapper(env=cyborg,agent_name='Blue')\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "print(obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only is the observation now a vector, but we can extract the action and observation spaces exactly like a gym environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step function also behaves like that of OpenAI gym. The info parameter contains a dictionary form of the standard results object for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "----------------------------------------------------------------------------\n",
      "-13.1\n",
      "----------------------------------------------------------------------------\n",
      "False\n",
      "----------------------------------------------------------------------------\n",
      "{'observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0]), 'next_observation': None, 'done': False, 'reward': -13.1, 'action': <CybORG.Shared.Actions.Action.Sleep object at 0x000001A9C278C850>, 'info': None, 'parameter_mask': None, 'action_space': 54, 'error': None, 'error_msg': None, 'action_name': None, 'selection_masks': None}\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "\n",
    "obs, reward, done, info = env.step(action)\n",
    "\n",
    "print(obs)\n",
    "print(76*'-')\n",
    "print(reward)\n",
    "print(76*'-')\n",
    "print(done)\n",
    "print(76*'-')\n",
    "print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
