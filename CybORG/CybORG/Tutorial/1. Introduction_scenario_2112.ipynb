{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the CybORG environment, it is necessary to import the CybORG class. CybORG stands for __Cyb__er __O__perations __R__esearch __G__ym, so remember to capitalise correctly when importing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\c21122256\\PycharmProjects\\CAGE-Challenge-1\\venv\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from CybORG import CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALthough CybORG uses an OpenAI gym API, it is not run by calling gym.make(). Instead it has to be manually instantiated. The constructor has two mandatory string parameters: a mode-type which specifies which engine will be used under the hood and the path to a .yaml scenario file which defines the network layout and agent action spaces.\n",
    "\n",
    "The only currently supported mode is simulation, while this challenge uses Scenario 1b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "path = str(inspect.getfile(CybORG))\n",
    "path = path[:-10] + '/Shared/Scenarios/Scenario_reduced_observation_2112_manual.yaml'\n",
    "\n",
    "env = CybORG(path, 'sim')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Agent with CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario 1b has multiple actors involved: Red team will be attacking the network, Blue team will be defending the network, while Green team represents noise generated by users. Normally the roles of Red and Green will be handled by internal rules-based agents, while Blue team interacts with the external API. However, for demonstration purposes, it will be easier to first examine a Red agent.\n",
    "\n",
    "CybORG uses an OpenAI Gym interface to interact with agents. Thus, we can begin the scenario by calling the reset method. It is necessary to specify which team you are on as a string parameter. Without using any wrappers, CybORG will return a results object which contains various bits of data. We can get the observation by accessing the corresponding attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': <TrinaryEnum.UNKNOWN: 2>, 'User0': {'Interface': [{'Interface Name': 'eth0', 'IP Address': IPv4Address('10.0.204.52'), 'Subnet': IPv4Network('10.0.204.48/28')}], 'Sessions': [{'Username': 'SYSTEM', 'ID': 0, 'Timeout': 0, 'PID': 13476, 'Type': <SessionType.RED_ABSTRACT_SESSION: 10>, 'Agent': 'Red'}], 'Processes': [{'PID': 13476, 'Username': 'SYSTEM'}], 'System info': {'Hostname': 'User0', 'OSType': <OperatingSystemType.WINDOWS: 2>, 'OSDistribution': <OperatingSystemDistribution.WINDOWS_SVR_2008: 4>, 'OSVersion': <OperatingSystemVersion.W6_1_7601: 13>, 'Architecture': <Architecture.x64: 2>}}}\n"
     ]
    }
   ],
   "source": [
    "results = env.reset(agent='Red')\n",
    "obs = results.observation\n",
    "print(obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the above observation outputs a messy dictionary. In order to understand raw CybORG observations, please go to the observation tutorial. We will show how to train a neural network-based agent with CybORG down below.\n",
    "\n",
    "Because of the complexties of Cybersecurity, the action space in CybORG is generated on the fly. For Scenario 1b, this only needs to be extracted at the beginning of the scenario. This can also be found in the results object. It is another messy dictionary, so we will only print out the keys. You can learn more in the action_space tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': {<class 'CybORG.Shared.Actions.Action.Sleep'>: True, <class 'CybORG.Shared.Actions.AbstractActions.DiscoverRemoteSystems.DiscoverRemoteSystems'>: True, <class 'CybORG.Shared.Actions.AbstractActions.DiscoverNetworkServices.DiscoverNetworkServices'>: True, <class 'CybORG.Shared.Actions.AbstractActions.ExploitRemoteService.ExploitRemoteService'>: True, <class 'CybORG.Shared.Actions.AbstractActions.PrivilegeEscalate.PrivilegeEscalate'>: True, <class 'CybORG.Shared.Actions.AbstractActions.Impact.Impact'>: True}, 'subnet': {IPv4Network('10.0.105.160/28'): False, IPv4Network('10.0.176.48/28'): False, IPv4Network('10.0.204.48/28'): True}, 'ip_address': {IPv4Address('10.0.105.161'): False, IPv4Address('10.0.105.164'): False, IPv4Address('10.0.105.168'): False, IPv4Address('10.0.176.54'): False, IPv4Address('10.0.176.62'): False, IPv4Address('10.0.204.52'): True, IPv4Address('10.0.204.60'): False}, 'session': {0: True}, 'username': {'root': False, 'ubuntu': False, 'Administrator': False, 'GreenAgent': False, 'vagrant': False, 'SYSTEM': False, 'www-data': False, 'pi': False}, 'password': {'vagrant': False, 'raspberry': False}, 'process': {1: False, 389: False, 407: False, 409: False, 560: False, 790: False, 802: False, 803: False, 807: False, 824: False, 825: False, 827: False, 832: False, 844: False, 847: False, 852: False, 853: False, 863: False, 867: False, 875: False, 884: False, 1370: False, 1432: False, 2288: False, 879: False, 19989: False, 23588: False, 3368: False, 4400: False, 4: False, 3404: False, 21312: False, 7341: False, 1091: False, 25192: False, 604: False, 1043: False, 6023: False, 4894: False, 19542: False, 13476: True, 10681: False, 7517: False}, 'port': {22: False, 135: False, 3389: False, 445: False, 139: False, 80: False, 443: False}, 'target_session': {0: False, 1: False, 2: False, 3: False, 4: False, 5: False, 6: False, 7: False}, 'agent': {'Red': True}, 'hostname': {'Defender': False, 'Enterprise1': False, 'Enterprise2': False, 'Op_Host0': False, 'Op_Server0': False, 'User0': True, 'User1': False}}\n",
      "['action', 'subnet', 'ip_address', 'session', 'username', 'password', 'process', 'port', 'target_session', 'agent', 'hostname']\n"
     ]
    }
   ],
   "source": [
    "action_space = results.action_space\n",
    "print(action_space)\n",
    "\n",
    "print(list(action_space.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like OpenAI gym, CybORG uses a step function to input actions and return results. The method itself requires two string parameters: agent is the name of the team that is taking the action and action is the action being performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscoverRemoteSystems 10.0.204.48/28\n"
     ]
    }
   ],
   "source": [
    "from CybORG.Agents import B_lineAgent,RedMeanderAgent\n",
    "from CybORG.Agents.SimpleAgents.B_line_2112 import B_lineAgent as B_lineAgent_2112\n",
    "\n",
    "agent = B_lineAgent_2112()\n",
    "\n",
    "action = agent.get_action(obs,action_space)\n",
    "\n",
    "results = env.step(agent='Red',action=action)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results object contains the new observation, reward and done attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': <TrinaryEnum.TRUE: 1>, '10.0.204.52': {'Interface': [{'IP Address': IPv4Address('10.0.204.52'), 'Subnet': IPv4Network('10.0.204.48/28')}]}, '10.0.204.60': {'Interface': [{'IP Address': IPv4Address('10.0.204.60'), 'Subnet': IPv4Network('10.0.204.48/28')}]}}\n",
      "----------------------------------------------------------------------------\n",
      "DiscoverRemoteSystems 10.0.204.48/28\n",
      "----------------------------------------------------------------------------\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(results.observation)\n",
    "print(76*'-')\n",
    "print(results.action)\n",
    "print(76*'-')\n",
    "print(results.done)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Opponents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, only Red Team performed any actions. In order to setup CybORG for the full challenge, we want a Blue Agent to be interacting with the external API while Red and Green take their actions automatically in the background.\n",
    "\n",
    "We can achieve this by specifying an agents dictionary to pass into CybORG when instantiating the class. Now, whenever the step function is called, the agents will take turn to perform their actions. Note that the turn order is Blue, Green then Red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscoverRemoteSystems 10.0.192.48/28\n",
      "-0.1\n",
      "DiscoverNetworkServices 10.0.192.53\n",
      "-0.1\n",
      "ExploitRemoteService 10.0.192.53\n",
      "-0.1\n",
      "-0.2\n",
      "PrivilegeEscalate User1\n",
      "-0.2\n",
      "DiscoverNetworkServices 10.0.94.197\n",
      "-0.2\n",
      "ExploitRemoteService 10.0.94.197\n",
      "-0.2\n",
      "PrivilegeEscalate Enterprise1\n",
      "-1.2\n",
      "DiscoverRemoteSystems 10.0.94.192/28\n",
      "-1.2\n",
      "DiscoverNetworkServices 10.0.94.194\n",
      "-1.2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[0;32m     17\u001b[0m     action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mget_action(obs,action_space\u001b[39m=\u001b[39maction_space)\n\u001b[1;32m---> 19\u001b[0m     results \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(agent\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mBlue\u001b[39;49m\u001b[39m'\u001b[39;49m,action\u001b[39m=\u001b[39;49maction)\n\u001b[0;32m     20\u001b[0m     obs \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mobservation\n\u001b[0;32m     21\u001b[0m     reward \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mreward\n",
      "File \u001b[1;32mc:\\users\\c21122256\\pycharmprojects\\cage-challenge-1\\cage-challenge-1\\cyborg\\CybORG\\CybORG.py:104\u001b[0m, in \u001b[0;36mCybORG.step\u001b[1;34m(self, agent, action, skip_valid_action_check)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, agent: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, action\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, skip_valid_action_check: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Results:\n\u001b[0;32m     89\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Performs a step in CybORG for the given agent.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m        the result of agent performing the action\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvironment_controller\u001b[39m.\u001b[39;49mstep(agent, action, skip_valid_action_check)\n",
      "File \u001b[1;32mc:\\users\\c21122256\\pycharmprojects\\cage-challenge-1\\cage-challenge-1\\cyborg\\CybORG\\Shared\\EnvironmentController.py:121\u001b[0m, in \u001b[0;36mEnvironmentController.step\u001b[1;34m(self, agent, action, skip_valid_action_check)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mfor\u001b[39;00m agent_name, agent_object \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent_interfaces\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    118\u001b[0m     \u001b[39m# pass observation to agent to get action\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m agent \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m agent \u001b[39m!=\u001b[39m agent_name:\n\u001b[1;32m--> 121\u001b[0m         agent_action \u001b[39m=\u001b[39m agent_object\u001b[39m.\u001b[39;49mget_action(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation[agent_name])\n\u001b[0;32m    123\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m         agent_action \u001b[39m=\u001b[39m action\n",
      "File \u001b[1;32mc:\\users\\c21122256\\pycharmprojects\\cage-challenge-1\\cage-challenge-1\\cyborg\\CybORG\\Shared\\AgentInterface.py:90\u001b[0m, in \u001b[0;36mAgentInterface.get_action\u001b[1;34m(self, observation, action_space)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m action_space \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     action_space \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mget_action_space()\n\u001b[1;32m---> 90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mget_action(observation, action_space)\n\u001b[0;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_action\n",
      "File \u001b[1;32mc:\\users\\c21122256\\pycharmprojects\\cage-challenge-1\\cage-challenge-1\\cyborg\\CybORG\\Agents\\SimpleAgents\\B_line_2112.py:80\u001b[0m, in \u001b[0;36mB_lineAgent.get_action\u001b[1;34m(self, observation, action_space)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39m# Exploit- Enterprise2\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction \u001b[39m==\u001b[39m \u001b[39m9\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_ip_address \u001b[39m=\u001b[39m [value \u001b[39mfor\u001b[39;49;00m key, value \u001b[39min\u001b[39;49;00m observation\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m key \u001b[39m!=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39msuccess\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mInterface\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mIP Address\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     81\u001b[0m     action \u001b[39m=\u001b[39m ExploitRemoteService(session\u001b[39m=\u001b[39msession, agent\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRed\u001b[39m\u001b[39m'\u001b[39m, ip_address\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_ip_address)\n\u001b[0;32m     82\u001b[0m     \u001b[39mprint\u001b[39m(action)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from CybORG.Agents import B_lineAgent, GreenAgent, BlueMonitorAgent,RedMeanderAgent\n",
    "from CybORG.Agents.SimpleAgents.B_line_2112 import B_lineAgent as B_lineAgent_2112\n",
    "\n",
    "agents = {\n",
    "    'Red': B_lineAgent_2112,\n",
    "    'Green': GreenAgent\n",
    "}\n",
    "\n",
    "env = CybORG(path,'sim',agents=agents)\n",
    "\n",
    "results = env.reset(agent='Blue')\n",
    "obs = results.observation\n",
    "action_space = results.action_space\n",
    "agent = BlueMonitorAgent()\n",
    "\n",
    "for step in range(1000):\n",
    "    action = agent.get_action(obs,action_space=action_space)\n",
    "\n",
    "    results = env.step(agent='Blue',action=action)\n",
    "    obs = results.observation\n",
    "    reward = results.reward\n",
    "    print(reward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Neural Network with CybORG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a Neural network with CybORG, we will need to import a wrapper. The Challenge Wrapper provides all the functionality needed for the Scenario1b challenge and makes the external api much more in line with OpenAI gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from CybORG.Agents.Wrappers import ChallengeWrapper\n",
    "cyborg = CybORG(path,'sim',agents=agents)\n",
    "env = ChallengeWrapper(env=cyborg,agent_name='Blue')\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "print(obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only is the observation now a vector, but we can extract the action and observation spaces exactly like a gym environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step function also behaves like that of OpenAI gym. The info parameter contains a dictionary form of the standard results object for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "----------------------------------------------------------------------------\n",
      "0.0\n",
      "----------------------------------------------------------------------------\n",
      "False\n",
      "----------------------------------------------------------------------------\n",
      "{'observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'next_observation': None, 'done': False, 'reward': 0.0, 'action': <CybORG.Shared.Actions.Action.Sleep object at 0x000002252A2AA0A0>, 'info': None, 'parameter_mask': None, 'action_space': 30, 'error': None, 'error_msg': None, 'action_name': None, 'selection_masks': None}\n"
     ]
    }
   ],
   "source": [
    "action = 0\n",
    "\n",
    "obs, reward, done, info = env.step(action)\n",
    "\n",
    "print(obs)\n",
    "print(76*'-')\n",
    "print(reward)\n",
    "print(76*'-')\n",
    "print(done)\n",
    "print(76*'-')\n",
    "print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
